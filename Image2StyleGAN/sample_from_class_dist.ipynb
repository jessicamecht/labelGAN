{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os, sys\n",
    "sys.path.append('/home/jessica/labelGAN/StyleGAN.pytorch/')\n",
    "from models.GAN import * \n",
    "from stylegan_layers import  G_mapping,G_synthesis\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from torchvision.utils import save_image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "g_all = nn.Sequential(OrderedDict([('g_mapping', G_mapping()),\n",
    "    #('truncation', Truncation(avg_latent)),\n",
    "    ('g_synthesis', G_synthesis(resolution=1024))    \n",
    "    ]))\n",
    "\n",
    "opts = {'mapping_layers': 8, 'truncation_psi': -1.}\n",
    "'''g_all = Generator(resolution=1024,\n",
    "                    num_channels=3,\n",
    "                    structure='linear',\n",
    "                    **opts)'''\n",
    "g_all = nn.Sequential(OrderedDict([('g_mapping', GMapping()),\n",
    "    #('truncation', Truncation(avg_latent)),\n",
    "    ('g_synthesis', GSynthesis(resolution=1024, depth=8))    \n",
    "    ]))\n",
    "#Load the pre-trained model\n",
    "g_all.load_state_dict(torch.load('/data1/jessica/data/labelGAN/checkpoints/styleGAN/GAN_GEN_8.pth', map_location=device), strict=False)\n",
    "g_all.eval()\n",
    "g_all.to(device)\n",
    "g_mapping, g_synthesis = g_all[0], g_all[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_latents_names = [elem.replace(\"latent_\", \"\").replace(\".npy\", \"\") for elem in os.listdir('/home/jessica/labelGAN/Image2StyleGAN/images/latents')]\n",
    "df = pd.read_csv(\"vinbig_25_samples.csv\")\n",
    "df_sampled = df[df.image_id.isin(image_latents_names)]\n",
    "kernel = 'exponential'\n",
    "for class_name in df.class_name.unique():\n",
    "   class_name = class_name.replace(\"/\", \"\").replace(\" \", \"\")\n",
    "   test = df_sampled[df_sampled.class_name == class_name].image_id\n",
    "   images = test.apply(lambda x: np.load(\"./images/latents/latent_\" + x + \".npy\"))\n",
    "   if len(images) == 0: continue\n",
    "   t = np.concatenate(np.array(images), axis=0)\n",
    "   t = t.reshape(t.shape[0], -1)# create an array of samples\n",
    "   samples = np.array(t)\n",
    "\n",
    "   # fit a kernel density estimator to the samples\n",
    "   kde = KernelDensity(bandwidth=0.5, kernel=kernel)\n",
    "   kde.fit(samples)\n",
    "\n",
    "   # sample from the kde\n",
    "   new_samples = kde.sample(100)\n",
    "   for i, latents in enumerate(new_samples):\n",
    "      latents = torch.tensor(latents.reshape(1, 18, 512)).to(\"cuda:2\").float()\n",
    "      syn_img = g_synthesis(latents, depth=8)\n",
    "      syn_img = (syn_img+1.0)/2.0\n",
    "      save_image(syn_img.clamp(0,1),f\"./images/generated_latents_from_class_distr/{class_name}_{i}_{kernel}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
