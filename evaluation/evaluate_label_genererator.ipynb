{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import sys\n",
    "sys.path.append('/home/jessica/labelGAN/datasetGAN_release/datasetGAN')\n",
    "from label_model import latent_classifier\n",
    "from train_dataset import labelDataLatent\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn \n",
    "device = \"cpu\"\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_latent_path = '/data3/jessica/data/labelGAN/test_images/latents/'\n",
    "checkpoint_path_label = '/data3/jessica/data/labelGAN/results_dir_multitask_generation_classif/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/data3/jessica/data/labelGAN/vinbig/train.csv'\n",
    "df = pd.read_csv(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data3/jessica/data/labelGAN/test_images/latents/\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(test_latent_path)\n",
    "files = sorted(files)\n",
    "label_data = labelDataLatent(files, test_latent_path, device, ret_id=True)\n",
    "train_loader_classif = DataLoader(dataset=label_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [elem.replace('latent_' ,\"\").replace(\".npy\", \"\") for elem in files]\n",
    "df = df[df.image_id.isin(ids)]\n",
    "df['class_name'] = df['class_name'].apply(lambda x: x.replace(\" \", \"\").replace(\"/\", \"\"))\n",
    "fil = df.groupby(by='image_id').class_name.apply(list)\n",
    "fil = fil.apply(lambda x: np.unique(np.array([few_shot_classes[xel] for xel in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latent_classifier(\n",
       "  (lin): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (label_layers): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Linear(in_features=32, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_classifier_instance = latent_classifier(15).to(device)\n",
    "checkpoint = torch.load(os.path.join(checkpoint_path_label, 'model_label_classif_number_' + '.pth'))\n",
    "label_classifier_instance.load_state_dict(checkpoint['model_state_dict'])\n",
    "label_classifier_instance.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim=1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim=1)\n",
    "\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "    acc = acc * 100\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_classes = {\"Nofinding\": 0,\n",
    "    'NoduleMass': 9,\n",
    "    'Infiltration': 7,\n",
    "    'LungOpacity': 3,\n",
    "    'Consolidation': 4,\n",
    "    'Pleuralthickening': 5,\n",
    "    'ILD': 6,\n",
    "    'Cardiomegaly': 2,\n",
    "    'Pulmonaryfibrosis': 8,\n",
    "    'Aorticenlargement': 1,\n",
    "    'Otherlesion': 10,\n",
    "    'Pleuraleffusion': 11,\n",
    "    'Calcification': 12,\n",
    "    'Atelectasis': 13,\n",
    "    'Pneumothorax': 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 15.03it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "accs = []\n",
    "losses = []\n",
    "ids = []\n",
    "all_probs = []\n",
    "sm = nn.Softmax(dim=1)\n",
    "corr_preds = []\n",
    "for X_batch, _, ids in tqdm(train_loader_classif):\n",
    "    labels = [fil[id] for id in ids]\n",
    "    X_batch = X_batch.detach()\n",
    "    y_pred = label_classifier_instance(X_batch.squeeze())\n",
    "    class_pred = sm(y_pred).argmax(-1).cpu().detach()\n",
    "    for i, pred in enumerate(class_pred):\n",
    "        corr_preds.append(pred.item() inlabels[i])\n",
    "    del X_batch, y_pred\n",
    "print(\"TEST ACC\": np.array(corr_preds).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1827645/3010653121.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(corr_preds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9, array([1, 2, 3, 7])],\n",
       "       [1, array([ 1,  3,  4,  5,  7,  8, 10, 13])],\n",
       "       [1, array([ 1,  2, 12])],\n",
       "       [8, array([ 3, 11])],\n",
       "       [1, array([ 5,  6,  7,  8, 10, 11, 13])],\n",
       "       [8, array([1, 3, 4, 5, 8, 9])],\n",
       "       [1, array([1, 2, 3, 5, 6, 8, 9])],\n",
       "       [0, array([0])],\n",
       "       [8, array([11, 14])],\n",
       "       [8, array([1, 2, 8])],\n",
       "       [1, array([0])],\n",
       "       [8, array([ 1,  5,  6, 10, 11])],\n",
       "       [1, array([ 4,  5,  7,  8,  9, 11, 13])],\n",
       "       [9, array([1, 2, 5, 8])],\n",
       "       [1, array([ 5,  7,  8, 13])],\n",
       "       [6, array([1, 2])],\n",
       "       [0, array([ 1,  2,  5, 10, 11])],\n",
       "       [0, array([ 2,  3,  5,  6,  8, 10, 11])],\n",
       "       [0, array([1, 5, 8, 9])],\n",
       "       [1, array([ 1,  2,  3,  7,  8, 10])],\n",
       "       [2, array([ 2,  3,  4,  7,  9, 11])],\n",
       "       [11, array([ 2,  3,  4,  5,  7, 11])],\n",
       "       [8, array([ 1,  3,  9, 10])],\n",
       "       [5, array([ 3,  7,  8, 11, 13])],\n",
       "       [1, array([ 1,  3,  5,  6,  7,  8, 13])],\n",
       "       [5, array([ 1,  5,  8,  9, 11, 14])],\n",
       "       [0, array([0])],\n",
       "       [6, array([ 1,  5,  8, 10, 12])],\n",
       "       [0, array([ 1,  2, 10, 12])],\n",
       "       [9, array([ 5,  8, 13])],\n",
       "       [0, array([ 3,  4,  7,  8, 11, 14])],\n",
       "       [1, array([1, 2])],\n",
       "       [0, array([ 5,  6, 10])],\n",
       "       [0, array([ 3,  5,  8, 11, 13])],\n",
       "       [9, array([ 5,  9, 10])],\n",
       "       [9, array([ 1,  2,  5,  8,  9, 10, 11, 13, 14])],\n",
       "       [8, array([ 3,  5,  7,  8, 13])],\n",
       "       [1, array([3, 4, 5, 7])],\n",
       "       [1, array([ 1,  3,  5, 10, 11, 13])],\n",
       "       [8, array([3, 4, 5, 7, 8])],\n",
       "       [1, array([ 1,  2,  6,  8,  9, 10])],\n",
       "       [8, array([ 5,  6,  7,  8,  9, 13])],\n",
       "       [8, array([1, 3, 4, 6, 9])],\n",
       "       [1, array([ 1,  5, 10, 11, 14])],\n",
       "       [1, array([ 1,  3,  4,  5,  7,  8,  9, 13])],\n",
       "       [0, array([ 3,  5,  8, 13])],\n",
       "       [8, array([ 1,  2,  3,  5,  7,  8, 10, 11])],\n",
       "       [1, array([ 3,  5,  7,  8, 10, 11, 13, 14])],\n",
       "       [8, array([ 1,  2,  3,  5,  8,  9, 11])],\n",
       "       [0, array([0])],\n",
       "       [0, array([ 1,  5, 11, 12])],\n",
       "       [1, array([1, 2, 5, 8])],\n",
       "       [0, array([ 3,  5,  8,  9, 10, 11, 12])],\n",
       "       [1, array([ 1,  5,  8,  9, 12])],\n",
       "       [0, array([ 3,  4,  7,  8,  9, 10, 11])],\n",
       "       [0, array([ 3,  5,  8, 10, 14])],\n",
       "       [9, array([0])],\n",
       "       [1, array([ 2,  3,  4,  5, 10, 13])],\n",
       "       [0, array([0])],\n",
       "       [8, array([0])],\n",
       "       [8, array([ 1,  2, 12])],\n",
       "       [1, array([0])],\n",
       "       [1, array([ 1,  2,  3,  4,  5,  9, 11])],\n",
       "       [8, array([ 5,  9, 10, 11, 12])],\n",
       "       [8, array([ 5,  7,  8, 11])],\n",
       "       [8, array([ 2,  3,  4,  5,  7, 10, 11, 13, 14])],\n",
       "       [1, array([ 1,  2,  9, 10, 12])],\n",
       "       [5, array([ 1,  2,  3,  4,  5,  7,  8, 11])],\n",
       "       [1, array([ 1,  3,  5,  6,  8, 10, 11, 13])],\n",
       "       [5, array([ 3,  4,  7, 11])],\n",
       "       [10, array([1, 2, 6, 8])],\n",
       "       [1, array([1, 2, 9])],\n",
       "       [0, array([ 1,  2,  5, 10, 12])],\n",
       "       [1, array([ 5,  6,  7,  8, 13])],\n",
       "       [1, array([ 1,  2,  8, 10, 12])],\n",
       "       [8, array([1, 3, 4, 8, 9])],\n",
       "       [1, array([1, 2])],\n",
       "       [1, array([ 1,  2,  5, 12])],\n",
       "       [1, array([1, 5, 8])],\n",
       "       [5, array([0])],\n",
       "       [8, array([ 1,  2,  5, 10, 12])],\n",
       "       [1, array([ 1,  3,  8, 11, 13])],\n",
       "       [1, array([ 1,  5,  7,  8, 12])],\n",
       "       [5, array([1, 2])]], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(corr_preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = next(iter(train_loader_classif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(all_preds) == np.array(all_labels)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 18, 512]), torch.Size([10, 1, 18, 512]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9854),\n",
       " tensor(1.0000),\n",
       " tensor(0.9995),\n",
       " tensor(0.9987),\n",
       " tensor(0.8178),\n",
       " tensor(0.9634),\n",
       " tensor(1.0000),\n",
       " tensor(0.9164),\n",
       " tensor(0.8237),\n",
       " tensor(0.9313),\n",
       " tensor(0.5444),\n",
       " tensor(0.9402),\n",
       " tensor(0.9990),\n",
       " tensor(0.7623),\n",
       " tensor(0.9866),\n",
       " tensor(0.7490),\n",
       " tensor(0.8728),\n",
       " tensor(0.9484),\n",
       " tensor(0.7625),\n",
       " tensor(0.9563),\n",
       " tensor(1.0000),\n",
       " tensor(1.),\n",
       " tensor(0.9842),\n",
       " tensor(0.9971),\n",
       " tensor(0.9899),\n",
       " tensor(0.9872),\n",
       " tensor(0.5705),\n",
       " tensor(1.0000),\n",
       " tensor(0.9148),\n",
       " tensor(0.9998),\n",
       " tensor(0.6106),\n",
       " tensor(0.6352),\n",
       " tensor(0.9742),\n",
       " tensor(0.4947),\n",
       " tensor(0.9953),\n",
       " tensor(0.9933),\n",
       " tensor(0.8699),\n",
       " tensor(0.9891),\n",
       " tensor(0.9264),\n",
       " tensor(0.9269),\n",
       " tensor(0.8208),\n",
       " tensor(0.9795),\n",
       " tensor(0.4131),\n",
       " tensor(0.9999),\n",
       " tensor(0.9026),\n",
       " tensor(0.9986),\n",
       " tensor(0.9229),\n",
       " tensor(0.9991),\n",
       " tensor(0.9731),\n",
       " tensor(0.7401),\n",
       " tensor(0.6989),\n",
       " tensor(0.9980),\n",
       " tensor(0.9998),\n",
       " tensor(0.9999),\n",
       " tensor(1.0000),\n",
       " tensor(0.9788),\n",
       " tensor(0.9853),\n",
       " tensor(0.9923),\n",
       " tensor(0.3498),\n",
       " tensor(0.6691),\n",
       " tensor(0.5324),\n",
       " tensor(0.9954),\n",
       " tensor(0.9990),\n",
       " tensor(0.6983),\n",
       " tensor(0.4398),\n",
       " tensor(0.9726),\n",
       " tensor(0.6845),\n",
       " tensor(0.9584),\n",
       " tensor(0.9594),\n",
       " tensor(0.9799),\n",
       " tensor(0.7313),\n",
       " tensor(0.9395),\n",
       " tensor(1.0000),\n",
       " tensor(0.9240),\n",
       " tensor(0.8341),\n",
       " tensor(0.9533),\n",
       " tensor(0.7856),\n",
       " tensor(0.8596),\n",
       " tensor(0.8590),\n",
       " tensor(0.9999),\n",
       " tensor(0.9809),\n",
       " tensor(0.8114),\n",
       " tensor(0.8839),\n",
       " tensor(0.5044)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
