2022-10-27 02:51:10 INFO: Using 1 GPUs.
2022-10-27 02:51:16 INFO: Loading generator from: ./output/models/GAN_GEN_5.pth
2022-10-27 02:51:16 INFO: Loading discriminator from: ./output/models/GAN_DIS_5.pth
2022-10-27 02:51:16 INFO: Loading generator optimizer from: ./output/models/GAN_GEN_OPTIM_5.pth
2022-10-27 02:51:16 INFO: Loading discriminator optimizer from: ./output/models/GAN_DIS_OPTIM_5.pth
2022-10-27 02:51:16 INFO: Starting the training process ... 

2022-10-27 02:51:16 INFO: Currently working on depth: 6
2022-10-27 02:51:16 INFO: Current resolution: 128 x 128
2022-10-27 02:51:16 INFO: Epoch: [1]
2022-10-27 02:51:21 INFO: Elapsed: [0:00:04] Step: 1  Batch: 1  D_Loss: 1.386325  G_Loss: 0.693356
2022-10-27 02:52:44 INFO: Elapsed: [0:01:28] Step: 33  Batch: 33  D_Loss: 1.386200  G_Loss: 0.693333
2022-10-27 02:54:08 INFO: Elapsed: [0:02:51] Step: 66  Batch: 66  D_Loss: 1.386169  G_Loss: 0.692477
2022-10-27 02:55:32 INFO: Elapsed: [0:04:15] Step: 99  Batch: 99  D_Loss: 1.386290  G_Loss: 0.688455
2022-10-27 02:56:56 INFO: Elapsed: [0:05:39] Step: 132  Batch: 132  D_Loss: 1.386192  G_Loss: 0.696071
2022-10-27 02:58:20 INFO: Elapsed: [0:07:03] Step: 165  Batch: 165  D_Loss: 1.385831  G_Loss: 0.694134
2022-10-27 02:59:44 INFO: Elapsed: [0:08:27] Step: 198  Batch: 198  D_Loss: 1.386144  G_Loss: 0.699338
2022-10-27 03:01:07 INFO: Elapsed: [0:09:50] Step: 231  Batch: 231  D_Loss: 1.387010  G_Loss: 0.696453
2022-10-27 03:02:31 INFO: Elapsed: [0:11:14] Step: 264  Batch: 264  D_Loss: 1.385974  G_Loss: 0.694607
2022-10-27 03:03:55 INFO: Elapsed: [0:12:38] Step: 297  Batch: 297  D_Loss: 1.386177  G_Loss: 0.693439
2022-10-27 03:05:08 INFO: Time taken for epoch: 0:13:51

2022-10-27 03:05:08 INFO: Saving the model to: ./output/models/GAN_GEN_5.pth

2022-10-27 03:05:10 INFO: Currently working on depth: 7
2022-10-27 03:05:10 INFO: Current resolution: 256 x 256
2022-10-27 03:05:10 INFO: Epoch: [1]
2022-10-27 03:05:14 INFO: Elapsed: [0:13:57] Step: 327  Batch: 1  D_Loss: 1.385959  G_Loss: 0.693311
2022-10-27 03:07:27 INFO: Elapsed: [0:16:11] Step: 392  Batch: 66  D_Loss: 1.386639  G_Loss: 0.693842
2022-10-27 03:09:44 INFO: Elapsed: [0:18:27] Step: 458  Batch: 132  D_Loss: 1.386638  G_Loss: 0.698232
2022-10-27 03:12:00 INFO: Elapsed: [0:20:43] Step: 524  Batch: 198  D_Loss: 1.384915  G_Loss: 0.696777
2022-10-27 03:14:15 INFO: Elapsed: [0:22:58] Step: 590  Batch: 264  D_Loss: 1.383808  G_Loss: 0.704879
2022-10-27 03:16:32 INFO: Elapsed: [0:25:15] Step: 656  Batch: 330  D_Loss: 1.386566  G_Loss: 0.676222
2022-10-27 03:18:47 INFO: Elapsed: [0:27:30] Step: 722  Batch: 396  D_Loss: 1.381024  G_Loss: 0.695419
2022-10-27 03:21:02 INFO: Elapsed: [0:29:45] Step: 788  Batch: 462  D_Loss: 1.366493  G_Loss: 0.739181
2022-10-27 03:23:19 INFO: Elapsed: [0:32:02] Step: 854  Batch: 528  D_Loss: 1.371276  G_Loss: 0.703496
2022-10-27 03:25:33 INFO: Elapsed: [0:34:16] Step: 920  Batch: 594  D_Loss: 1.383799  G_Loss: 0.662409
2022-10-27 03:27:34 INFO: Time taken for epoch: 0:22:24

2022-10-27 03:27:34 INFO: Saving the model to: ./output/models/GAN_GEN_6.pth

2022-10-27 03:27:35 INFO: Epoch: [2]
2022-10-27 03:27:37 INFO: Elapsed: [0:36:21] Step: 979  Batch: 1  D_Loss: 1.374524  G_Loss: 0.684623
2022-10-27 03:29:52 INFO: Elapsed: [0:38:35] Step: 1044  Batch: 66  D_Loss: 1.373429  G_Loss: 0.661697
2022-10-27 03:32:07 INFO: Elapsed: [0:40:50] Step: 1110  Batch: 132  D_Loss: 1.377752  G_Loss: 0.733442
2022-10-27 03:34:24 INFO: Elapsed: [0:43:07] Step: 1176  Batch: 198  D_Loss: 1.384294  G_Loss: 0.687308
2022-10-27 03:36:39 INFO: Elapsed: [0:45:22] Step: 1242  Batch: 264  D_Loss: 1.403225  G_Loss: 0.723332
2022-10-27 03:38:54 INFO: Elapsed: [0:47:37] Step: 1308  Batch: 330  D_Loss: 1.381449  G_Loss: 0.649894
2022-10-27 03:41:08 INFO: Elapsed: [0:49:52] Step: 1374  Batch: 396  D_Loss: 1.384915  G_Loss: 0.696086
2022-10-27 03:43:24 INFO: Elapsed: [0:52:07] Step: 1440  Batch: 462  D_Loss: 1.382967  G_Loss: 0.691690
2022-10-27 03:45:39 INFO: Elapsed: [0:54:22] Step: 1506  Batch: 528  D_Loss: 1.378281  G_Loss: 0.663903
2022-10-27 03:47:54 INFO: Elapsed: [0:56:38] Step: 1572  Batch: 594  D_Loss: 1.391822  G_Loss: 0.681231
2022-10-27 03:49:54 INFO: Time taken for epoch: 0:22:18

2022-10-27 03:49:54 INFO: Epoch: [3]
2022-10-27 03:49:56 INFO: Elapsed: [0:58:39] Step: 1631  Batch: 1  D_Loss: 1.563656  G_Loss: 0.824956
2022-10-27 03:52:09 INFO: Elapsed: [1:00:53] Step: 1696  Batch: 66  D_Loss: 1.383718  G_Loss: 0.698613
2022-10-27 03:54:25 INFO: Elapsed: [1:03:09] Step: 1762  Batch: 132  D_Loss: 1.390058  G_Loss: 0.698616
2022-10-27 03:56:41 INFO: Elapsed: [1:05:25] Step: 1828  Batch: 198  D_Loss: 1.391441  G_Loss: 0.651361
2022-10-27 03:58:58 INFO: Elapsed: [1:07:41] Step: 1894  Batch: 264  D_Loss: 1.379015  G_Loss: 0.686963
2022-10-27 04:01:13 INFO: Elapsed: [1:09:56] Step: 1960  Batch: 330  D_Loss: 1.374553  G_Loss: 0.739111
2022-10-27 04:03:28 INFO: Elapsed: [1:12:11] Step: 2026  Batch: 396  D_Loss: 1.382932  G_Loss: 0.698457
2022-10-27 04:05:43 INFO: Elapsed: [1:14:27] Step: 2092  Batch: 462  D_Loss: 1.390725  G_Loss: 0.707143
2022-10-27 04:07:59 INFO: Elapsed: [1:16:42] Step: 2158  Batch: 528  D_Loss: 1.384492  G_Loss: 0.651755
2022-10-27 04:10:15 INFO: Elapsed: [1:18:58] Step: 2224  Batch: 594  D_Loss: 1.383415  G_Loss: 0.701228
2022-10-27 04:12:14 INFO: Time taken for epoch: 0:22:20

2022-10-27 04:12:14 INFO: Epoch: [4]
2022-10-27 04:12:16 INFO: Elapsed: [1:20:59] Step: 2283  Batch: 1  D_Loss: 1.383366  G_Loss: 0.691483
2022-10-27 04:14:29 INFO: Elapsed: [1:23:13] Step: 2348  Batch: 66  D_Loss: 1.385307  G_Loss: 0.693777
2022-10-27 04:16:45 INFO: Elapsed: [1:25:28] Step: 2414  Batch: 132  D_Loss: 1.381571  G_Loss: 0.688428
2022-10-27 04:19:01 INFO: Elapsed: [1:27:44] Step: 2480  Batch: 198  D_Loss: 1.377450  G_Loss: 0.650070
2022-10-27 04:21:16 INFO: Elapsed: [1:29:59] Step: 2546  Batch: 264  D_Loss: 1.383584  G_Loss: 0.687015
2022-10-27 04:23:32 INFO: Elapsed: [1:32:15] Step: 2612  Batch: 330  D_Loss: 1.380279  G_Loss: 0.749350
2022-10-27 04:25:46 INFO: Elapsed: [1:34:30] Step: 2678  Batch: 396  D_Loss: 1.382033  G_Loss: 0.660559
2022-10-27 04:28:02 INFO: Elapsed: [1:36:45] Step: 2744  Batch: 462  D_Loss: 1.382699  G_Loss: 0.700005
2022-10-27 04:30:17 INFO: Elapsed: [1:39:00] Step: 2810  Batch: 528  D_Loss: 1.378648  G_Loss: 0.703017
2022-10-27 04:32:33 INFO: Elapsed: [1:41:16] Step: 2876  Batch: 594  D_Loss: 1.375185  G_Loss: 0.724048
2022-10-27 04:34:33 INFO: Time taken for epoch: 0:22:18

2022-10-27 04:34:33 INFO: Epoch: [5]
2022-10-27 04:34:35 INFO: Elapsed: [1:43:18] Step: 2935  Batch: 1  D_Loss: 1.375455  G_Loss: 0.767100
2022-10-27 04:36:49 INFO: Elapsed: [1:45:33] Step: 3000  Batch: 66  D_Loss: 1.383292  G_Loss: 0.673563
2022-10-27 04:39:07 INFO: Elapsed: [1:47:50] Step: 3066  Batch: 132  D_Loss: 1.393325  G_Loss: 0.697577
2022-10-27 04:41:23 INFO: Elapsed: [1:50:06] Step: 3132  Batch: 198  D_Loss: 1.381212  G_Loss: 0.695892
2022-10-27 04:43:40 INFO: Elapsed: [1:52:23] Step: 3198  Batch: 264  D_Loss: 1.388384  G_Loss: 0.768389
2022-10-27 04:45:57 INFO: Elapsed: [1:54:41] Step: 3264  Batch: 330  D_Loss: 1.381629  G_Loss: 0.684774
2022-10-27 04:48:14 INFO: Elapsed: [1:56:57] Step: 3330  Batch: 396  D_Loss: 1.487119  G_Loss: 0.515738
2022-10-27 04:50:29 INFO: Elapsed: [1:59:12] Step: 3396  Batch: 462  D_Loss: 1.382532  G_Loss: 0.690220
2022-10-27 04:52:46 INFO: Elapsed: [2:01:29] Step: 3462  Batch: 528  D_Loss: 1.387232  G_Loss: 0.696174
2022-10-27 04:55:04 INFO: Elapsed: [2:03:47] Step: 3528  Batch: 594  D_Loss: 1.378383  G_Loss: 0.683649
2022-10-27 04:57:04 INFO: Time taken for epoch: 0:22:30

2022-10-27 04:57:04 INFO: Epoch: [6]
2022-10-27 04:57:06 INFO: Elapsed: [2:05:49] Step: 3587  Batch: 1  D_Loss: 1.381838  G_Loss: 0.737407
2022-10-27 04:59:20 INFO: Elapsed: [2:08:03] Step: 3652  Batch: 66  D_Loss: 1.388475  G_Loss: 0.690447
2022-10-27 05:01:36 INFO: Elapsed: [2:10:19] Step: 3718  Batch: 132  D_Loss: 1.370345  G_Loss: 0.592455
2022-10-27 05:03:51 INFO: Elapsed: [2:12:34] Step: 3784  Batch: 198  D_Loss: 1.380845  G_Loss: 0.716084
2022-10-27 05:06:06 INFO: Elapsed: [2:14:50] Step: 3850  Batch: 264  D_Loss: 1.356884  G_Loss: 0.678279
2022-10-27 05:08:24 INFO: Elapsed: [2:17:07] Step: 3916  Batch: 330  D_Loss: 1.365186  G_Loss: 0.662833
2022-10-27 05:10:40 INFO: Elapsed: [2:19:24] Step: 3982  Batch: 396  D_Loss: 1.352399  G_Loss: 0.538650
2022-10-27 05:12:56 INFO: Elapsed: [2:21:39] Step: 4048  Batch: 462  D_Loss: 1.355189  G_Loss: 0.939465
2022-10-27 05:15:13 INFO: Elapsed: [2:23:56] Step: 4114  Batch: 528  D_Loss: 1.300653  G_Loss: 0.905903
2022-10-27 05:17:30 INFO: Elapsed: [2:26:14] Step: 4180  Batch: 594  D_Loss: 1.331837  G_Loss: 0.756666
2022-10-27 05:19:31 INFO: Time taken for epoch: 0:22:27

2022-10-27 05:19:31 INFO: Epoch: [7]
2022-10-27 05:19:33 INFO: Elapsed: [2:28:16] Step: 4239  Batch: 1  D_Loss: 1.389797  G_Loss: 1.055662
2022-10-27 05:21:47 INFO: Elapsed: [2:30:30] Step: 4304  Batch: 66  D_Loss: 1.385089  G_Loss: 0.712552
2022-10-27 05:24:00 INFO: Elapsed: [2:32:44] Step: 4370  Batch: 132  D_Loss: 1.314460  G_Loss: 0.776014
2022-10-27 05:26:17 INFO: Elapsed: [2:35:00] Step: 4436  Batch: 198  D_Loss: 1.406794  G_Loss: 0.973132
2022-10-27 05:28:34 INFO: Elapsed: [2:37:17] Step: 4502  Batch: 264  D_Loss: 1.318863  G_Loss: 0.959610
2022-10-27 05:30:52 INFO: Elapsed: [2:39:35] Step: 4568  Batch: 330  D_Loss: 1.265604  G_Loss: 0.806303
2022-10-27 05:33:08 INFO: Elapsed: [2:41:51] Step: 4634  Batch: 396  D_Loss: 1.326650  G_Loss: 0.714900
2022-10-27 05:35:24 INFO: Elapsed: [2:44:07] Step: 4700  Batch: 462  D_Loss: 1.449826  G_Loss: 0.788575
2022-10-27 05:37:40 INFO: Elapsed: [2:46:24] Step: 4766  Batch: 528  D_Loss: 1.317057  G_Loss: 0.908694
2022-10-27 05:39:58 INFO: Elapsed: [2:48:41] Step: 4832  Batch: 594  D_Loss: 1.292246  G_Loss: 0.854425
2022-10-27 05:41:57 INFO: Time taken for epoch: 0:22:25

2022-10-27 05:41:57 INFO: Epoch: [8]
2022-10-27 05:41:59 INFO: Elapsed: [2:50:42] Step: 4891  Batch: 1  D_Loss: 1.334367  G_Loss: 0.774533
2022-10-27 05:44:12 INFO: Elapsed: [2:52:55] Step: 4956  Batch: 66  D_Loss: 1.303381  G_Loss: 0.912771
2022-10-27 05:46:29 INFO: Elapsed: [2:55:13] Step: 5022  Batch: 132  D_Loss: 1.329249  G_Loss: 0.820801
2022-10-27 05:48:45 INFO: Elapsed: [2:57:28] Step: 5088  Batch: 198  D_Loss: 1.335941  G_Loss: 0.745559
2022-10-27 05:51:01 INFO: Elapsed: [2:59:45] Step: 5154  Batch: 264  D_Loss: 1.321948  G_Loss: 0.787628
2022-10-27 05:53:18 INFO: Elapsed: [3:02:01] Step: 5220  Batch: 330  D_Loss: 1.348256  G_Loss: 1.072059
2022-10-27 05:55:35 INFO: Elapsed: [3:04:18] Step: 5286  Batch: 396  D_Loss: 1.300930  G_Loss: 0.845978
2022-10-27 05:57:51 INFO: Elapsed: [3:06:34] Step: 5352  Batch: 462  D_Loss: 1.338095  G_Loss: 0.642271
2022-10-27 06:00:08 INFO: Elapsed: [3:08:51] Step: 5418  Batch: 528  D_Loss: 1.315273  G_Loss: 0.677101
2022-10-27 06:02:24 INFO: Elapsed: [3:11:07] Step: 5484  Batch: 594  D_Loss: 1.310070  G_Loss: 0.727280
2022-10-27 06:04:26 INFO: Time taken for epoch: 0:22:29

2022-10-27 06:04:26 INFO: Epoch: [9]
2022-10-27 06:04:28 INFO: Elapsed: [3:13:12] Step: 5543  Batch: 1  D_Loss: 1.285227  G_Loss: 0.627481
2022-10-27 06:06:44 INFO: Elapsed: [3:15:27] Step: 5608  Batch: 66  D_Loss: 1.351805  G_Loss: 0.973299
2022-10-27 06:09:01 INFO: Elapsed: [3:17:44] Step: 5674  Batch: 132  D_Loss: 1.333147  G_Loss: 0.859052
2022-10-27 06:11:16 INFO: Elapsed: [3:19:59] Step: 5740  Batch: 198  D_Loss: 1.261972  G_Loss: 0.861740
2022-10-27 06:13:32 INFO: Elapsed: [3:22:15] Step: 5806  Batch: 264  D_Loss: 1.308178  G_Loss: 0.793496
2022-10-27 06:15:49 INFO: Elapsed: [3:24:32] Step: 5872  Batch: 330  D_Loss: 1.354905  G_Loss: 0.862171
2022-10-27 06:18:05 INFO: Elapsed: [3:26:48] Step: 5938  Batch: 396  D_Loss: 1.296614  G_Loss: 0.920549
2022-10-27 06:20:21 INFO: Elapsed: [3:29:04] Step: 6004  Batch: 462  D_Loss: 1.385056  G_Loss: 0.609057
2022-10-27 06:22:37 INFO: Elapsed: [3:31:21] Step: 6070  Batch: 528  D_Loss: 1.334300  G_Loss: 0.918262
2022-10-27 06:24:54 INFO: Elapsed: [3:33:37] Step: 6136  Batch: 594  D_Loss: 1.349573  G_Loss: 0.771877
2022-10-27 06:26:54 INFO: Time taken for epoch: 0:22:28

2022-10-27 06:26:54 INFO: Epoch: [10]
2022-10-27 06:26:57 INFO: Elapsed: [3:35:40] Step: 6195  Batch: 1  D_Loss: 1.303935  G_Loss: 0.832391
2022-10-27 06:29:11 INFO: Elapsed: [3:37:54] Step: 6260  Batch: 66  D_Loss: 1.353567  G_Loss: 0.880723
2022-10-27 06:31:28 INFO: Elapsed: [3:40:11] Step: 6326  Batch: 132  D_Loss: 1.382425  G_Loss: 0.919869
2022-10-27 06:33:44 INFO: Elapsed: [3:42:27] Step: 6392  Batch: 198  D_Loss: 1.320344  G_Loss: 0.780648
2022-10-27 06:36:01 INFO: Elapsed: [3:44:44] Step: 6458  Batch: 264  D_Loss: 1.331626  G_Loss: 0.867772
2022-10-27 06:38:17 INFO: Elapsed: [3:47:00] Step: 6524  Batch: 330  D_Loss: 1.327718  G_Loss: 0.729732
2022-10-27 06:40:32 INFO: Elapsed: [3:49:15] Step: 6590  Batch: 396  D_Loss: 1.349506  G_Loss: 0.923273
2022-10-27 06:42:47 INFO: Elapsed: [3:51:30] Step: 6656  Batch: 462  D_Loss: 1.283701  G_Loss: 0.788039
2022-10-27 06:45:03 INFO: Elapsed: [3:53:46] Step: 6722  Batch: 528  D_Loss: 1.324615  G_Loss: 0.701241
2022-10-27 06:47:19 INFO: Elapsed: [3:56:02] Step: 6788  Batch: 594  D_Loss: 1.305647  G_Loss: 0.789830
2022-10-27 06:49:18 INFO: Time taken for epoch: 0:22:23

2022-10-27 06:49:19 INFO: Saving the model to: ./output/models/GAN_GEN_6.pth

2022-10-27 06:49:20 INFO: Epoch: [11]
2022-10-27 06:49:22 INFO: Elapsed: [3:58:05] Step: 6847  Batch: 1  D_Loss: 1.319469  G_Loss: 0.742307
2022-10-27 06:51:36 INFO: Elapsed: [4:00:19] Step: 6912  Batch: 66  D_Loss: 1.347918  G_Loss: 0.630577
2022-10-27 06:53:52 INFO: Elapsed: [4:02:35] Step: 6978  Batch: 132  D_Loss: 1.367534  G_Loss: 0.932968
2022-10-27 06:56:07 INFO: Elapsed: [4:04:51] Step: 7044  Batch: 198  D_Loss: 1.334513  G_Loss: 0.708618
2022-10-27 06:58:23 INFO: Elapsed: [4:07:06] Step: 7110  Batch: 264  D_Loss: 1.306047  G_Loss: 0.809850
2022-10-27 07:00:39 INFO: Elapsed: [4:09:22] Step: 7176  Batch: 330  D_Loss: 1.323995  G_Loss: 0.701502
2022-10-27 07:02:54 INFO: Elapsed: [4:11:38] Step: 7242  Batch: 396  D_Loss: 1.311720  G_Loss: 0.710509
2022-10-27 07:05:11 INFO: Elapsed: [4:13:54] Step: 7308  Batch: 462  D_Loss: 1.349672  G_Loss: 0.931482
2022-10-27 07:07:27 INFO: Elapsed: [4:16:10] Step: 7374  Batch: 528  D_Loss: 1.263658  G_Loss: 1.152710
2022-10-27 07:09:42 INFO: Elapsed: [4:18:25] Step: 7440  Batch: 594  D_Loss: 1.285755  G_Loss: 0.843418
2022-10-27 07:11:41 INFO: Time taken for epoch: 0:22:21

2022-10-27 07:11:41 INFO: Epoch: [12]
2022-10-27 07:11:44 INFO: Elapsed: [4:20:27] Step: 7499  Batch: 1  D_Loss: 1.307226  G_Loss: 0.835259
2022-10-27 07:13:57 INFO: Elapsed: [4:22:40] Step: 7564  Batch: 66  D_Loss: 1.364342  G_Loss: 0.853271
2022-10-27 07:16:12 INFO: Elapsed: [4:24:55] Step: 7630  Batch: 132  D_Loss: 1.316902  G_Loss: 0.814385
2022-10-27 07:18:27 INFO: Elapsed: [4:27:10] Step: 7696  Batch: 198  D_Loss: 1.329550  G_Loss: 0.852919
2022-10-27 07:20:44 INFO: Elapsed: [4:29:27] Step: 7762  Batch: 264  D_Loss: 1.332938  G_Loss: 0.702993
2022-10-27 07:22:59 INFO: Elapsed: [4:31:42] Step: 7828  Batch: 330  D_Loss: 1.402222  G_Loss: 0.706204
2022-10-27 07:25:15 INFO: Elapsed: [4:33:58] Step: 7894  Batch: 396  D_Loss: 1.272009  G_Loss: 0.836315
2022-10-27 07:27:30 INFO: Elapsed: [4:36:14] Step: 7960  Batch: 462  D_Loss: 1.357755  G_Loss: 0.608925
2022-10-27 07:29:46 INFO: Elapsed: [4:38:29] Step: 8026  Batch: 528  D_Loss: 1.388335  G_Loss: 0.884202
2022-10-27 07:32:03 INFO: Elapsed: [4:40:47] Step: 8092  Batch: 594  D_Loss: 1.255910  G_Loss: 0.952064
2022-10-27 07:34:03 INFO: Time taken for epoch: 0:22:21

2022-10-27 07:34:03 INFO: Epoch: [13]
2022-10-27 07:34:05 INFO: Elapsed: [4:42:49] Step: 8151  Batch: 1  D_Loss: 1.397674  G_Loss: 0.559013
2022-10-27 07:36:19 INFO: Elapsed: [4:45:02] Step: 8216  Batch: 66  D_Loss: 1.345335  G_Loss: 0.816932
2022-10-27 07:38:35 INFO: Elapsed: [4:47:19] Step: 8282  Batch: 132  D_Loss: 1.317937  G_Loss: 0.694599
2022-10-27 07:40:52 INFO: Elapsed: [4:49:35] Step: 8348  Batch: 198  D_Loss: 1.306853  G_Loss: 0.758910
2022-10-27 07:43:07 INFO: Elapsed: [4:51:50] Step: 8414  Batch: 264  D_Loss: 1.356449  G_Loss: 0.719175
2022-10-27 07:45:23 INFO: Elapsed: [4:54:06] Step: 8480  Batch: 330  D_Loss: 1.262053  G_Loss: 0.742937
2022-10-27 07:47:39 INFO: Elapsed: [4:56:22] Step: 8546  Batch: 396  D_Loss: 1.350793  G_Loss: 0.674551
2022-10-27 07:49:56 INFO: Elapsed: [4:58:39] Step: 8612  Batch: 462  D_Loss: 1.286830  G_Loss: 0.780131
2022-10-27 07:52:11 INFO: Elapsed: [5:00:54] Step: 8678  Batch: 528  D_Loss: 1.311472  G_Loss: 0.880337
2022-10-27 07:54:26 INFO: Elapsed: [5:03:09] Step: 8744  Batch: 594  D_Loss: 1.320052  G_Loss: 0.876247
2022-10-27 07:56:25 INFO: Time taken for epoch: 0:22:21

2022-10-27 07:56:25 INFO: Epoch: [14]
2022-10-27 07:56:27 INFO: Elapsed: [5:05:10] Step: 8803  Batch: 1  D_Loss: 1.344506  G_Loss: 0.708442
2022-10-27 07:58:41 INFO: Elapsed: [5:07:24] Step: 8868  Batch: 66  D_Loss: 1.287768  G_Loss: 0.807937
2022-10-27 08:00:57 INFO: Elapsed: [5:09:41] Step: 8934  Batch: 132  D_Loss: 1.357053  G_Loss: 0.822236
2022-10-27 08:03:12 INFO: Elapsed: [5:11:55] Step: 9000  Batch: 198  D_Loss: 1.350644  G_Loss: 0.907528
2022-10-27 08:05:28 INFO: Elapsed: [5:14:11] Step: 9066  Batch: 264  D_Loss: 1.315552  G_Loss: 0.777313
2022-10-27 08:07:43 INFO: Elapsed: [5:16:27] Step: 9132  Batch: 330  D_Loss: 1.264850  G_Loss: 0.738557
2022-10-27 08:09:58 INFO: Elapsed: [5:18:41] Step: 9198  Batch: 396  D_Loss: 1.422465  G_Loss: 0.915255
2022-10-27 08:12:13 INFO: Elapsed: [5:20:57] Step: 9264  Batch: 462  D_Loss: 1.286416  G_Loss: 0.942493
2022-10-27 08:14:28 INFO: Elapsed: [5:23:11] Step: 9330  Batch: 528  D_Loss: 1.375000  G_Loss: 0.991769
2022-10-27 08:16:43 INFO: Elapsed: [5:25:27] Step: 9396  Batch: 594  D_Loss: 1.334154  G_Loss: 0.802864
2022-10-27 08:18:41 INFO: Time taken for epoch: 0:22:16

2022-10-27 08:18:41 INFO: Epoch: [15]
2022-10-27 08:18:43 INFO: Elapsed: [5:27:27] Step: 9455  Batch: 1  D_Loss: 1.409029  G_Loss: 0.590519
2022-10-27 08:20:57 INFO: Elapsed: [5:29:40] Step: 9520  Batch: 66  D_Loss: 1.280992  G_Loss: 0.850567
2022-10-27 08:23:12 INFO: Elapsed: [5:31:55] Step: 9586  Batch: 132  D_Loss: 1.269167  G_Loss: 0.827060
2022-10-27 08:25:27 INFO: Elapsed: [5:34:10] Step: 9652  Batch: 198  D_Loss: 1.350262  G_Loss: 0.793271
2022-10-27 08:27:43 INFO: Elapsed: [5:36:26] Step: 9718  Batch: 264  D_Loss: 1.341027  G_Loss: 0.610877
2022-10-27 08:29:58 INFO: Elapsed: [5:38:42] Step: 9784  Batch: 330  D_Loss: 1.261635  G_Loss: 0.930132
2022-10-27 08:32:14 INFO: Elapsed: [5:40:57] Step: 9850  Batch: 396  D_Loss: 1.287730  G_Loss: 0.760036
2022-10-27 08:34:29 INFO: Elapsed: [5:43:12] Step: 9916  Batch: 462  D_Loss: 1.328681  G_Loss: 0.840889
2022-10-27 08:36:44 INFO: Elapsed: [5:45:27] Step: 9982  Batch: 528  D_Loss: 1.261302  G_Loss: 0.880836
2022-10-27 08:39:00 INFO: Elapsed: [5:47:44] Step: 10048  Batch: 594  D_Loss: 1.339702  G_Loss: 0.798466
2022-10-27 08:41:00 INFO: Time taken for epoch: 0:22:19

2022-10-27 08:41:00 INFO: Epoch: [16]
2022-10-27 08:41:02 INFO: Elapsed: [5:49:46] Step: 10107  Batch: 1  D_Loss: 1.325905  G_Loss: 0.688352
2022-10-27 08:43:16 INFO: Elapsed: [5:52:00] Step: 10172  Batch: 66  D_Loss: 1.277094  G_Loss: 0.822795
2022-10-27 08:45:32 INFO: Elapsed: [5:54:16] Step: 10238  Batch: 132  D_Loss: 1.330341  G_Loss: 0.791154
2022-10-27 08:47:49 INFO: Elapsed: [5:56:32] Step: 10304  Batch: 198  D_Loss: 1.278302  G_Loss: 0.843315
2022-10-27 08:50:04 INFO: Elapsed: [5:58:47] Step: 10370  Batch: 264  D_Loss: 1.338637  G_Loss: 0.801748
2022-10-27 08:52:21 INFO: Elapsed: [6:01:04] Step: 10436  Batch: 330  D_Loss: 1.326946  G_Loss: 0.831867
2022-10-27 08:54:36 INFO: Elapsed: [6:03:19] Step: 10502  Batch: 396  D_Loss: 1.417554  G_Loss: 0.907335
2022-10-27 08:56:52 INFO: Elapsed: [6:05:35] Step: 10568  Batch: 462  D_Loss: 1.342860  G_Loss: 0.749312
2022-10-27 08:59:06 INFO: Elapsed: [6:07:49] Step: 10634  Batch: 528  D_Loss: 1.333289  G_Loss: 0.802264
2022-10-27 09:01:22 INFO: Elapsed: [6:10:06] Step: 10700  Batch: 594  D_Loss: 1.451916  G_Loss: 0.942201
2022-10-27 09:03:21 INFO: Time taken for epoch: 0:22:20

2022-10-27 09:03:22 INFO: Saving the model to: ./output/models/GAN_GEN_6.pth

2022-10-27 09:03:23 INFO: Training completed.

