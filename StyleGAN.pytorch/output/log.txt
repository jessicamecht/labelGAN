2023-02-03 11:07:23 INFO: Using 1 GPUs.
2023-02-03 11:07:25 INFO: Loading generator from: /data1/jessica/data/labelGAN/checkpoints/styleGAN/GAN_GEN_7.pth
2023-02-03 11:07:32 INFO: Loading discriminator from: /data1/jessica/data/labelGAN/checkpoints/styleGAN/GAN_DIS_7.pth
2023-02-03 11:07:32 INFO: Loading generator optimizer from: /data1/jessica/data/labelGAN/checkpoints/styleGAN/GAN_GEN_OPTIM_7.pth
2023-02-03 11:07:33 INFO: Loading discriminator optimizer from: /data1/jessica/data/labelGAN/checkpoints/styleGAN/GAN_DIS_OPTIM_7.pth
2023-02-03 11:07:34 INFO: Starting the training process ... 

2023-02-03 11:07:34 INFO: Currently working on depth: 8
2023-02-03 11:07:34 INFO: Current resolution: 512 x 512
2023-02-03 11:07:34 INFO: Epoch: [1]
2023-02-03 11:07:54 INFO: Elapsed: [0:00:19] Step: 1  Batch: 1  D_Loss: 1.751688  G_Loss: 0.301947
2023-02-03 11:17:57 INFO: Elapsed: [0:10:22] Step: 66  Batch: 66  D_Loss: 0.979540  G_Loss: 1.117644
2023-02-03 11:28:07 INFO: Elapsed: [0:20:33] Step: 132  Batch: 132  D_Loss: 1.215283  G_Loss: 0.871399
2023-02-03 11:38:18 INFO: Elapsed: [0:30:43] Step: 198  Batch: 198  D_Loss: 1.181516  G_Loss: 0.770812
2023-02-03 11:48:38 INFO: Elapsed: [0:41:04] Step: 264  Batch: 264  D_Loss: 1.096400  G_Loss: 1.470818
2023-02-03 11:59:07 INFO: Elapsed: [0:51:33] Step: 330  Batch: 330  D_Loss: 1.526266  G_Loss: 0.639257
2023-02-03 12:09:28 INFO: Elapsed: [1:01:54] Step: 396  Batch: 396  D_Loss: 0.955143  G_Loss: 1.410893
2023-02-03 12:19:56 INFO: Elapsed: [1:12:22] Step: 462  Batch: 462  D_Loss: 1.243203  G_Loss: 0.890543
2023-02-03 12:30:13 INFO: Elapsed: [1:22:39] Step: 528  Batch: 528  D_Loss: 1.063532  G_Loss: 1.420678
2023-02-03 12:40:30 INFO: Elapsed: [1:32:56] Step: 594  Batch: 594  D_Loss: 1.091327  G_Loss: 0.963032
2023-02-03 12:49:24 INFO: Time taken for epoch: 1:41:49

2023-02-03 12:49:24 INFO: Saving the model to: ./output/models/GAN_GEN_7.pth

2023-02-03 12:49:25 INFO: Epoch: [2]
2023-02-03 12:49:34 INFO: Elapsed: [1:42:00] Step: 652  Batch: 1  D_Loss: 1.143740  G_Loss: 1.355829
2023-02-03 13:00:25 INFO: Elapsed: [1:52:51] Step: 717  Batch: 66  D_Loss: 0.989374  G_Loss: 1.086449
2023-02-03 13:12:17 INFO: Elapsed: [2:04:42] Step: 783  Batch: 132  D_Loss: 1.087533  G_Loss: 0.950544
2023-02-03 13:24:08 INFO: Elapsed: [2:16:34] Step: 849  Batch: 198  D_Loss: 1.063943  G_Loss: 1.212724
2023-02-03 13:36:00 INFO: Elapsed: [2:28:26] Step: 915  Batch: 264  D_Loss: 1.316627  G_Loss: 0.831808
2023-02-03 13:47:53 INFO: Elapsed: [2:40:19] Step: 981  Batch: 330  D_Loss: 1.090361  G_Loss: 0.905387
2023-02-03 13:59:01 INFO: Elapsed: [2:51:27] Step: 1047  Batch: 396  D_Loss: 1.017644  G_Loss: 0.976632
2023-02-03 14:09:17 INFO: Elapsed: [3:01:43] Step: 1113  Batch: 462  D_Loss: 1.144130  G_Loss: 1.217388
2023-02-03 14:20:23 INFO: Elapsed: [3:12:48] Step: 1179  Batch: 528  D_Loss: 1.395322  G_Loss: 0.631821
2023-02-03 14:32:26 INFO: Elapsed: [3:24:51] Step: 1245  Batch: 594  D_Loss: 1.276296  G_Loss: 0.666366
2023-02-03 14:42:56 INFO: Time taken for epoch: 1:53:31

2023-02-03 14:42:56 INFO: Epoch: [3]
2023-02-03 14:43:07 INFO: Elapsed: [3:35:33] Step: 1303  Batch: 1  D_Loss: 0.916860  G_Loss: 1.267870
2023-02-03 14:54:56 INFO: Elapsed: [3:47:22] Step: 1368  Batch: 66  D_Loss: 1.124574  G_Loss: 0.783997
2023-02-03 15:06:57 INFO: Elapsed: [3:59:23] Step: 1434  Batch: 132  D_Loss: 1.057498  G_Loss: 0.710155
2023-02-03 15:18:57 INFO: Elapsed: [4:11:23] Step: 1500  Batch: 198  D_Loss: 0.964834  G_Loss: 0.975806
2023-02-03 15:30:57 INFO: Elapsed: [4:23:23] Step: 1566  Batch: 264  D_Loss: 0.941359  G_Loss: 0.696715
2023-02-03 15:42:57 INFO: Elapsed: [4:35:23] Step: 1632  Batch: 330  D_Loss: 1.054955  G_Loss: 1.488835
2023-02-03 15:54:59 INFO: Elapsed: [4:47:24] Step: 1698  Batch: 396  D_Loss: 1.057649  G_Loss: 0.962308
2023-02-03 16:06:58 INFO: Elapsed: [4:59:24] Step: 1764  Batch: 462  D_Loss: 0.993575  G_Loss: 0.788213
2023-02-03 16:18:58 INFO: Elapsed: [5:11:24] Step: 1830  Batch: 528  D_Loss: 1.083728  G_Loss: 0.542852
2023-02-03 16:30:59 INFO: Elapsed: [5:23:25] Step: 1896  Batch: 594  D_Loss: 1.202667  G_Loss: 0.647233
2023-02-03 16:41:22 INFO: Time taken for epoch: 1:58:26

2023-02-03 16:41:22 INFO: Epoch: [4]
2023-02-03 16:41:33 INFO: Elapsed: [5:33:59] Step: 1954  Batch: 1  D_Loss: 0.933822  G_Loss: 0.954646
2023-02-03 16:53:20 INFO: Elapsed: [5:45:46] Step: 2019  Batch: 66  D_Loss: 1.075031  G_Loss: 1.216294
2023-02-03 17:05:19 INFO: Elapsed: [5:57:45] Step: 2085  Batch: 132  D_Loss: 0.997570  G_Loss: 1.399704
2023-02-03 17:17:19 INFO: Elapsed: [6:09:45] Step: 2151  Batch: 198  D_Loss: 0.872713  G_Loss: 1.434942
2023-02-03 17:29:19 INFO: Elapsed: [6:21:44] Step: 2217  Batch: 264  D_Loss: 0.904304  G_Loss: 0.917764
2023-02-03 17:41:18 INFO: Elapsed: [6:33:44] Step: 2283  Batch: 330  D_Loss: 1.054197  G_Loss: 1.545865
2023-02-03 17:53:18 INFO: Elapsed: [6:45:44] Step: 2349  Batch: 396  D_Loss: 1.170854  G_Loss: 0.869273
2023-02-03 18:05:18 INFO: Elapsed: [6:57:44] Step: 2415  Batch: 462  D_Loss: 0.946909  G_Loss: 1.088214
2023-02-03 18:17:18 INFO: Elapsed: [7:09:43] Step: 2481  Batch: 528  D_Loss: 1.187512  G_Loss: 0.950660
2023-02-03 18:29:17 INFO: Elapsed: [7:21:43] Step: 2547  Batch: 594  D_Loss: 0.799861  G_Loss: 1.625016
2023-02-03 18:39:40 INFO: Time taken for epoch: 1:58:17

2023-02-03 18:39:40 INFO: Saving the model to: ./output/models/GAN_GEN_7.pth

2023-02-03 18:39:41 INFO: Currently working on depth: 9
2023-02-03 18:39:41 INFO: Current resolution: 1024 x 1024
2023-02-03 18:39:41 INFO: Epoch: [1]
2023-02-03 18:40:26 INFO: Elapsed: [7:32:51] Step: 2605  Batch: 1  D_Loss: 0.753034  G_Loss: 1.333444
2023-02-03 19:06:54 INFO: Elapsed: [7:59:20] Step: 2670  Batch: 66  D_Loss: 0.393724  G_Loss: 2.257478
2023-02-03 19:33:51 INFO: Elapsed: [8:26:17] Step: 2736  Batch: 132  D_Loss: 0.641919  G_Loss: 1.595593
2023-02-03 20:00:53 INFO: Elapsed: [8:53:18] Step: 2802  Batch: 198  D_Loss: 0.645944  G_Loss: 3.009664
2023-02-03 20:27:57 INFO: Elapsed: [9:20:23] Step: 2868  Batch: 264  D_Loss: 0.346890  G_Loss: 2.374542
2023-02-03 20:55:06 INFO: Elapsed: [9:47:31] Step: 2934  Batch: 330  D_Loss: 0.739862  G_Loss: 3.026395
2023-02-03 21:23:34 INFO: Elapsed: [10:15:59] Step: 3000  Batch: 396  D_Loss: 0.576469  G_Loss: 1.852715
2023-02-03 21:52:10 INFO: Elapsed: [10:44:36] Step: 3066  Batch: 462  D_Loss: 0.967496  G_Loss: 2.536484
2023-02-03 22:20:45 INFO: Elapsed: [11:13:10] Step: 3132  Batch: 528  D_Loss: 0.365650  G_Loss: 2.638549
2023-02-03 22:49:19 INFO: Elapsed: [11:41:44] Step: 3198  Batch: 594  D_Loss: 0.718676  G_Loss: 2.456728
2023-02-03 23:14:02 INFO: Time taken for epoch: 4:34:20

2023-02-03 23:14:02 INFO: Saving the model to: ./output/models/GAN_GEN_8.pth

2023-02-03 23:14:03 INFO: Epoch: [2]
2023-02-03 23:14:28 INFO: Elapsed: [12:06:54] Step: 3256  Batch: 1  D_Loss: 0.385316  G_Loss: 2.518771
2023-02-03 23:42:35 INFO: Elapsed: [12:35:01] Step: 3321  Batch: 66  D_Loss: 0.886891  G_Loss: 1.587073
2023-02-04 00:11:10 INFO: Elapsed: [13:03:35] Step: 3387  Batch: 132  D_Loss: 0.726934  G_Loss: 2.336935
2023-02-04 00:39:42 INFO: Elapsed: [13:32:08] Step: 3453  Batch: 198  D_Loss: 0.423719  G_Loss: 2.646661
2023-02-04 01:08:12 INFO: Elapsed: [14:00:38] Step: 3519  Batch: 264  D_Loss: 0.759356  G_Loss: 2.734143
2023-02-04 01:36:45 INFO: Elapsed: [14:29:10] Step: 3585  Batch: 330  D_Loss: 1.006071  G_Loss: 0.765294
2023-02-04 02:05:19 INFO: Elapsed: [14:57:45] Step: 3651  Batch: 396  D_Loss: 0.617559  G_Loss: 1.721780
2023-02-04 02:33:49 INFO: Elapsed: [15:26:15] Step: 3717  Batch: 462  D_Loss: 0.961841  G_Loss: 1.686677
2023-02-04 03:02:17 INFO: Elapsed: [15:54:43] Step: 3783  Batch: 528  D_Loss: 0.338056  G_Loss: 2.178108
2023-02-04 03:30:48 INFO: Elapsed: [16:23:13] Step: 3849  Batch: 594  D_Loss: 0.765776  G_Loss: 1.118384
2023-02-04 03:55:28 INFO: Time taken for epoch: 4:41:24

2023-02-04 03:55:28 INFO: Epoch: [3]
2023-02-04 03:55:53 INFO: Elapsed: [16:48:19] Step: 3907  Batch: 1  D_Loss: 0.988053  G_Loss: 1.093768
2023-02-04 04:23:51 INFO: Elapsed: [17:16:16] Step: 3972  Batch: 66  D_Loss: 0.698546  G_Loss: 2.254066
2023-02-04 04:52:15 INFO: Elapsed: [17:44:40] Step: 4038  Batch: 132  D_Loss: 0.461981  G_Loss: 2.607898
2023-02-04 05:20:37 INFO: Elapsed: [18:13:03] Step: 4104  Batch: 198  D_Loss: 0.410956  G_Loss: 2.690031
2023-02-04 05:48:59 INFO: Elapsed: [18:41:25] Step: 4170  Batch: 264  D_Loss: 0.757054  G_Loss: 3.134861
2023-02-04 06:17:24 INFO: Elapsed: [19:09:50] Step: 4236  Batch: 330  D_Loss: 1.166143  G_Loss: 1.922648
2023-02-04 06:45:47 INFO: Elapsed: [19:38:12] Step: 4302  Batch: 396  D_Loss: 1.524054  G_Loss: 0.523462
2023-02-04 07:14:17 INFO: Elapsed: [20:06:43] Step: 4368  Batch: 462  D_Loss: 0.905873  G_Loss: 2.104211
2023-02-04 07:42:49 INFO: Elapsed: [20:35:15] Step: 4434  Batch: 528  D_Loss: 0.904578  G_Loss: 0.723271
2023-02-04 08:11:21 INFO: Elapsed: [21:03:46] Step: 4500  Batch: 594  D_Loss: 0.725080  G_Loss: 1.695947
2023-02-04 08:36:03 INFO: Time taken for epoch: 4:40:35

2023-02-04 08:36:03 INFO: Epoch: [4]
2023-02-04 08:36:28 INFO: Elapsed: [21:28:54] Step: 4558  Batch: 1  D_Loss: 0.851649  G_Loss: 0.952694
2023-02-04 09:04:36 INFO: Elapsed: [21:57:02] Step: 4623  Batch: 66  D_Loss: 0.758935  G_Loss: 1.063388
2023-02-04 09:33:11 INFO: Elapsed: [22:25:37] Step: 4689  Batch: 132  D_Loss: 0.952291  G_Loss: 1.137114
2023-02-04 10:01:44 INFO: Elapsed: [22:54:10] Step: 4755  Batch: 198  D_Loss: 1.353394  G_Loss: 2.093126
2023-02-04 10:30:18 INFO: Elapsed: [23:22:43] Step: 4821  Batch: 264  D_Loss: 1.358307  G_Loss: 1.382489
2023-02-04 10:58:50 INFO: Elapsed: [23:51:16] Step: 4887  Batch: 330  D_Loss: 0.886429  G_Loss: 0.965662
2023-02-04 11:27:23 INFO: Elapsed: [1 day, 0:19:49] Step: 4953  Batch: 396  D_Loss: 0.503984  G_Loss: 3.106216
2023-02-04 11:55:55 INFO: Elapsed: [1 day, 0:48:21] Step: 5019  Batch: 462  D_Loss: 1.257649  G_Loss: 0.939022
2023-02-04 12:24:27 INFO: Elapsed: [1 day, 1:16:52] Step: 5085  Batch: 528  D_Loss: 1.083339  G_Loss: 2.294703
2023-02-04 12:54:07 INFO: Elapsed: [1 day, 1:46:33] Step: 5151  Batch: 594  D_Loss: 0.854918  G_Loss: 1.269138
2023-02-04 13:20:02 INFO: Time taken for epoch: 4:43:59

2023-02-04 13:20:02 INFO: Epoch: [5]
2023-02-04 13:20:29 INFO: Elapsed: [1 day, 2:12:55] Step: 5209  Batch: 1  D_Loss: 0.662423  G_Loss: 2.200444
2023-02-04 13:49:43 INFO: Elapsed: [1 day, 2:42:09] Step: 5274  Batch: 66  D_Loss: 1.121724  G_Loss: 0.838854
2023-02-04 14:19:16 INFO: Elapsed: [1 day, 3:11:42] Step: 5340  Batch: 132  D_Loss: 0.749873  G_Loss: 1.608415
2023-02-04 14:47:48 INFO: Elapsed: [1 day, 3:40:13] Step: 5406  Batch: 198  D_Loss: 0.815014  G_Loss: 2.773170
2023-02-04 15:16:19 INFO: Elapsed: [1 day, 4:08:44] Step: 5472  Batch: 264  D_Loss: 0.774282  G_Loss: 2.449391
2023-02-04 15:44:49 INFO: Elapsed: [1 day, 4:37:15] Step: 5538  Batch: 330  D_Loss: 0.663647  G_Loss: 2.121998
2023-02-04 16:13:18 INFO: Elapsed: [1 day, 5:05:44] Step: 5604  Batch: 396  D_Loss: 0.978498  G_Loss: 1.456042
2023-02-04 16:41:50 INFO: Elapsed: [1 day, 5:34:16] Step: 5670  Batch: 462  D_Loss: 1.005523  G_Loss: 1.641528
2023-02-04 17:10:21 INFO: Elapsed: [1 day, 6:02:46] Step: 5736  Batch: 528  D_Loss: 1.564631  G_Loss: 0.345731
2023-02-04 17:38:50 INFO: Elapsed: [1 day, 6:31:16] Step: 5802  Batch: 594  D_Loss: 1.297128  G_Loss: 0.761535
2023-02-04 18:03:31 INFO: Time taken for epoch: 4:43:29

2023-02-04 18:03:31 INFO: Epoch: [6]
2023-02-04 18:03:57 INFO: Elapsed: [1 day, 6:56:22] Step: 5860  Batch: 1  D_Loss: 1.000082  G_Loss: 1.262328
2023-02-04 18:32:01 INFO: Elapsed: [1 day, 7:24:27] Step: 5925  Batch: 66  D_Loss: 1.058725  G_Loss: 1.260098
2023-02-04 19:00:29 INFO: Elapsed: [1 day, 7:52:55] Step: 5991  Batch: 132  D_Loss: 0.903357  G_Loss: 0.729232
2023-02-04 19:28:33 INFO: Elapsed: [1 day, 8:20:59] Step: 6057  Batch: 198  D_Loss: 0.890831  G_Loss: 1.197282
2023-02-04 19:55:56 INFO: Elapsed: [1 day, 8:48:22] Step: 6123  Batch: 264  D_Loss: 0.665112  G_Loss: 1.724524
2023-02-04 20:23:22 INFO: Elapsed: [1 day, 9:15:48] Step: 6189  Batch: 330  D_Loss: 0.738006  G_Loss: 1.984228
2023-02-04 20:50:48 INFO: Elapsed: [1 day, 9:43:14] Step: 6255  Batch: 396  D_Loss: 1.048495  G_Loss: 2.246298
2023-02-04 21:18:14 INFO: Elapsed: [1 day, 10:10:40] Step: 6321  Batch: 462  D_Loss: 0.985710  G_Loss: 2.800570
2023-02-04 21:45:45 INFO: Elapsed: [1 day, 10:38:11] Step: 6387  Batch: 528  D_Loss: 0.848404  G_Loss: 0.837317
2023-02-04 22:10:55 INFO: Elapsed: [1 day, 11:03:20] Step: 6453  Batch: 594  D_Loss: 0.714021  G_Loss: 2.264016
2023-02-04 22:31:51 INFO: Time taken for epoch: 4:28:20

2023-02-04 22:31:51 INFO: Epoch: [7]
2023-02-04 22:32:13 INFO: Elapsed: [1 day, 11:24:38] Step: 6511  Batch: 1  D_Loss: 1.022158  G_Loss: 1.327469
2023-02-04 22:56:00 INFO: Elapsed: [1 day, 11:48:26] Step: 6576  Batch: 66  D_Loss: 0.980555  G_Loss: 1.104877
2023-02-04 23:20:14 INFO: Elapsed: [1 day, 12:12:40] Step: 6642  Batch: 132  D_Loss: 0.956089  G_Loss: 0.760731
2023-02-04 23:44:18 INFO: Elapsed: [1 day, 12:36:44] Step: 6708  Batch: 198  D_Loss: 0.865765  G_Loss: 1.610910
2023-02-05 00:08:24 INFO: Elapsed: [1 day, 13:00:50] Step: 6774  Batch: 264  D_Loss: 1.189710  G_Loss: 0.782261
2023-02-05 00:32:35 INFO: Elapsed: [1 day, 13:25:01] Step: 6840  Batch: 330  D_Loss: 1.179870  G_Loss: 0.591555
2023-02-05 00:56:42 INFO: Elapsed: [1 day, 13:49:08] Step: 6906  Batch: 396  D_Loss: 0.979727  G_Loss: 1.496637
2023-02-05 01:20:53 INFO: Elapsed: [1 day, 14:13:19] Step: 6972  Batch: 462  D_Loss: 0.722580  G_Loss: 1.737363
2023-02-05 01:45:02 INFO: Elapsed: [1 day, 14:37:28] Step: 7038  Batch: 528  D_Loss: 1.066744  G_Loss: 2.440320
2023-02-05 02:09:15 INFO: Elapsed: [1 day, 15:01:41] Step: 7104  Batch: 594  D_Loss: 1.070930  G_Loss: 1.225557
2023-02-05 02:30:12 INFO: Time taken for epoch: 3:58:20

2023-02-05 02:30:12 INFO: Epoch: [8]
2023-02-05 02:30:33 INFO: Elapsed: [1 day, 15:22:59] Step: 7162  Batch: 1  D_Loss: 1.035565  G_Loss: 1.457869
2023-02-05 02:54:17 INFO: Elapsed: [1 day, 15:46:43] Step: 7227  Batch: 66  D_Loss: 0.844926  G_Loss: 1.306488
2023-02-05 03:18:27 INFO: Elapsed: [1 day, 16:10:53] Step: 7293  Batch: 132  D_Loss: 0.921115  G_Loss: 2.358911
2023-02-05 03:42:37 INFO: Elapsed: [1 day, 16:35:03] Step: 7359  Batch: 198  D_Loss: 1.144341  G_Loss: 1.711643
2023-02-05 04:06:46 INFO: Elapsed: [1 day, 16:59:12] Step: 7425  Batch: 264  D_Loss: 0.898731  G_Loss: 0.987092
2023-02-05 04:30:58 INFO: Elapsed: [1 day, 17:23:24] Step: 7491  Batch: 330  D_Loss: 0.949778  G_Loss: 1.827440
2023-02-05 04:55:07 INFO: Elapsed: [1 day, 17:47:33] Step: 7557  Batch: 396  D_Loss: 1.077305  G_Loss: 1.532299
2023-02-05 05:19:10 INFO: Elapsed: [1 day, 18:11:35] Step: 7623  Batch: 462  D_Loss: 0.758467  G_Loss: 1.393985
2023-02-05 05:43:20 INFO: Elapsed: [1 day, 18:35:46] Step: 7689  Batch: 528  D_Loss: 1.018076  G_Loss: 1.797363
2023-02-05 06:07:29 INFO: Elapsed: [1 day, 18:59:55] Step: 7755  Batch: 594  D_Loss: 0.965616  G_Loss: 1.352836
2023-02-05 06:28:25 INFO: Time taken for epoch: 3:58:13

2023-02-05 06:28:25 INFO: Epoch: [9]
2023-02-05 06:28:47 INFO: Elapsed: [1 day, 19:21:12] Step: 7813  Batch: 1  D_Loss: 1.066721  G_Loss: 1.743830
2023-02-05 06:52:35 INFO: Elapsed: [1 day, 19:45:01] Step: 7878  Batch: 66  D_Loss: 1.034509  G_Loss: 0.887519
2023-02-05 07:16:47 INFO: Elapsed: [1 day, 20:09:12] Step: 7944  Batch: 132  D_Loss: 0.908833  G_Loss: 1.508914
2023-02-05 07:41:00 INFO: Elapsed: [1 day, 20:33:26] Step: 8010  Batch: 198  D_Loss: 0.882823  G_Loss: 1.888737
2023-02-05 08:05:13 INFO: Elapsed: [1 day, 20:57:39] Step: 8076  Batch: 264  D_Loss: 0.957953  G_Loss: 1.809854
2023-02-05 08:29:25 INFO: Elapsed: [1 day, 21:21:50] Step: 8142  Batch: 330  D_Loss: 1.119939  G_Loss: 2.439238
2023-02-05 08:53:34 INFO: Elapsed: [1 day, 21:45:59] Step: 8208  Batch: 396  D_Loss: 1.131739  G_Loss: 1.562126
2023-02-05 09:17:43 INFO: Elapsed: [1 day, 22:10:08] Step: 8274  Batch: 462  D_Loss: 1.043398  G_Loss: 0.983876
2023-02-05 09:41:53 INFO: Elapsed: [1 day, 22:34:19] Step: 8340  Batch: 528  D_Loss: 0.896406  G_Loss: 1.011659
2023-02-05 10:06:05 INFO: Elapsed: [1 day, 22:58:31] Step: 8406  Batch: 594  D_Loss: 1.021121  G_Loss: 1.332635
2023-02-05 10:27:00 INFO: Time taken for epoch: 3:58:35

2023-02-05 10:27:00 INFO: Epoch: [10]
2023-02-05 10:27:22 INFO: Elapsed: [1 day, 23:19:47] Step: 8464  Batch: 1  D_Loss: 1.063414  G_Loss: 1.693183
2023-02-05 10:51:10 INFO: Elapsed: [1 day, 23:43:36] Step: 8529  Batch: 66  D_Loss: 1.050434  G_Loss: 1.600935
2023-02-05 11:15:23 INFO: Elapsed: [2 days, 0:07:48] Step: 8595  Batch: 132  D_Loss: 1.073276  G_Loss: 0.688903
2023-02-05 11:39:35 INFO: Elapsed: [2 days, 0:32:00] Step: 8661  Batch: 198  D_Loss: 1.233287  G_Loss: 0.865359
2023-02-05 12:03:43 INFO: Elapsed: [2 days, 0:56:09] Step: 8727  Batch: 264  D_Loss: 1.014374  G_Loss: 1.375799
2023-02-05 12:27:54 INFO: Elapsed: [2 days, 1:20:19] Step: 8793  Batch: 330  D_Loss: 0.980452  G_Loss: 1.125304
2023-02-05 12:52:06 INFO: Elapsed: [2 days, 1:44:32] Step: 8859  Batch: 396  D_Loss: 0.828255  G_Loss: 1.202774
2023-02-05 13:16:17 INFO: Elapsed: [2 days, 2:08:43] Step: 8925  Batch: 462  D_Loss: 1.261914  G_Loss: 2.244999
2023-02-05 13:40:29 INFO: Elapsed: [2 days, 2:32:54] Step: 8991  Batch: 528  D_Loss: 1.083705  G_Loss: 0.937394
2023-02-05 14:04:38 INFO: Elapsed: [2 days, 2:57:04] Step: 9057  Batch: 594  D_Loss: 1.079567  G_Loss: 0.660158
2023-02-05 14:25:36 INFO: Time taken for epoch: 3:58:36

2023-02-05 14:25:36 INFO: Saving the model to: ./output/models/GAN_GEN_8.pth

2023-02-05 14:25:37 INFO: Epoch: [11]
2023-02-05 14:25:59 INFO: Elapsed: [2 days, 3:18:25] Step: 9115  Batch: 1  D_Loss: 0.749957  G_Loss: 1.251292
2023-02-05 14:49:49 INFO: Elapsed: [2 days, 3:42:15] Step: 9180  Batch: 66  D_Loss: 0.977284  G_Loss: 0.726042
2023-02-05 15:14:00 INFO: Elapsed: [2 days, 4:06:26] Step: 9246  Batch: 132  D_Loss: 1.642381  G_Loss: 0.655121
2023-02-05 15:38:12 INFO: Elapsed: [2 days, 4:30:38] Step: 9312  Batch: 198  D_Loss: 0.890272  G_Loss: 1.991082
2023-02-05 16:02:23 INFO: Elapsed: [2 days, 4:54:49] Step: 9378  Batch: 264  D_Loss: 0.998267  G_Loss: 0.989645
2023-02-05 16:26:34 INFO: Elapsed: [2 days, 5:18:59] Step: 9444  Batch: 330  D_Loss: 1.057447  G_Loss: 1.135743
2023-02-05 16:50:45 INFO: Elapsed: [2 days, 5:43:10] Step: 9510  Batch: 396  D_Loss: 1.046728  G_Loss: 0.909957
2023-02-05 17:14:55 INFO: Elapsed: [2 days, 6:07:20] Step: 9576  Batch: 462  D_Loss: 1.224781  G_Loss: 0.857149
2023-02-05 17:39:05 INFO: Elapsed: [2 days, 6:31:31] Step: 9642  Batch: 528  D_Loss: 1.119412  G_Loss: 1.563006
2023-02-05 18:03:18 INFO: Elapsed: [2 days, 6:55:43] Step: 9708  Batch: 594  D_Loss: 1.634635  G_Loss: 0.486412
2023-02-05 18:24:14 INFO: Time taken for epoch: 3:58:36

2023-02-05 18:24:14 INFO: Epoch: [12]
2023-02-05 18:24:36 INFO: Elapsed: [2 days, 7:17:02] Step: 9766  Batch: 1  D_Loss: 0.813258  G_Loss: 2.558498
2023-02-05 18:48:24 INFO: Elapsed: [2 days, 7:40:49] Step: 9831  Batch: 66  D_Loss: 1.251320  G_Loss: 0.934175
2023-02-05 19:12:34 INFO: Elapsed: [2 days, 8:05:00] Step: 9897  Batch: 132  D_Loss: 1.448910  G_Loss: 0.672095
2023-02-05 19:36:45 INFO: Elapsed: [2 days, 8:29:10] Step: 9963  Batch: 198  D_Loss: 0.894374  G_Loss: 1.119724
2023-02-05 20:00:57 INFO: Elapsed: [2 days, 8:53:23] Step: 10029  Batch: 264  D_Loss: 1.016409  G_Loss: 2.223195
2023-02-05 20:25:11 INFO: Elapsed: [2 days, 9:17:36] Step: 10095  Batch: 330  D_Loss: 1.004092  G_Loss: 1.121311
2023-02-05 20:49:25 INFO: Elapsed: [2 days, 9:41:51] Step: 10161  Batch: 396  D_Loss: 1.071897  G_Loss: 1.364282
2023-02-05 21:13:39 INFO: Elapsed: [2 days, 10:06:05] Step: 10227  Batch: 462  D_Loss: 1.072235  G_Loss: 1.475988
2023-02-05 21:37:53 INFO: Elapsed: [2 days, 10:30:19] Step: 10293  Batch: 528  D_Loss: 0.842745  G_Loss: 1.443754
2023-02-05 22:02:06 INFO: Elapsed: [2 days, 10:54:31] Step: 10359  Batch: 594  D_Loss: 1.044209  G_Loss: 0.887866
2023-02-05 22:23:04 INFO: Time taken for epoch: 3:58:49

2023-02-05 22:23:04 INFO: Epoch: [13]
2023-02-05 22:23:26 INFO: Elapsed: [2 days, 11:15:51] Step: 10417  Batch: 1  D_Loss: 1.380528  G_Loss: 0.816886
2023-02-05 22:47:17 INFO: Elapsed: [2 days, 11:39:42] Step: 10482  Batch: 66  D_Loss: 0.739789  G_Loss: 2.803305
2023-02-05 23:11:31 INFO: Elapsed: [2 days, 12:03:57] Step: 10548  Batch: 132  D_Loss: 1.090073  G_Loss: 1.429610
2023-02-05 23:35:44 INFO: Elapsed: [2 days, 12:28:10] Step: 10614  Batch: 198  D_Loss: 0.967896  G_Loss: 1.786744
2023-02-05 23:59:59 INFO: Elapsed: [2 days, 12:52:25] Step: 10680  Batch: 264  D_Loss: 1.025076  G_Loss: 1.389542
2023-02-06 00:24:14 INFO: Elapsed: [2 days, 13:16:40] Step: 10746  Batch: 330  D_Loss: 1.082196  G_Loss: 2.254967
2023-02-06 00:48:26 INFO: Elapsed: [2 days, 13:40:52] Step: 10812  Batch: 396  D_Loss: 1.049510  G_Loss: 0.923324
2023-02-06 01:12:40 INFO: Elapsed: [2 days, 14:05:05] Step: 10878  Batch: 462  D_Loss: 1.086175  G_Loss: 3.058681
2023-02-06 01:36:53 INFO: Elapsed: [2 days, 14:29:19] Step: 10944  Batch: 528  D_Loss: 1.085564  G_Loss: 1.148629
2023-02-06 02:01:11 INFO: Elapsed: [2 days, 14:53:37] Step: 11010  Batch: 594  D_Loss: 1.152754  G_Loss: 0.817635
2023-02-06 02:22:08 INFO: Time taken for epoch: 3:59:03

2023-02-06 02:22:08 INFO: Epoch: [14]
2023-02-06 02:22:29 INFO: Elapsed: [2 days, 15:14:55] Step: 11068  Batch: 1  D_Loss: 0.901177  G_Loss: 1.004849
2023-02-06 02:46:19 INFO: Elapsed: [2 days, 15:38:44] Step: 11133  Batch: 66  D_Loss: 1.221228  G_Loss: 0.783067
2023-02-06 03:10:30 INFO: Elapsed: [2 days, 16:02:55] Step: 11199  Batch: 132  D_Loss: 0.754300  G_Loss: 2.018783
2023-02-06 03:34:40 INFO: Elapsed: [2 days, 16:27:05] Step: 11265  Batch: 198  D_Loss: 0.821686  G_Loss: 1.111792
2023-02-06 03:58:51 INFO: Elapsed: [2 days, 16:51:16] Step: 11331  Batch: 264  D_Loss: 0.805667  G_Loss: 1.702915
2023-02-06 04:23:07 INFO: Elapsed: [2 days, 17:15:33] Step: 11397  Batch: 330  D_Loss: 0.996137  G_Loss: 1.816964
2023-02-06 04:47:18 INFO: Elapsed: [2 days, 17:39:43] Step: 11463  Batch: 396  D_Loss: 0.863608  G_Loss: 1.107348
2023-02-06 05:11:28 INFO: Elapsed: [2 days, 18:03:54] Step: 11529  Batch: 462  D_Loss: 1.117704  G_Loss: 1.316206
2023-02-06 05:35:39 INFO: Elapsed: [2 days, 18:28:05] Step: 11595  Batch: 528  D_Loss: 0.833809  G_Loss: 1.371336
2023-02-06 05:59:51 INFO: Elapsed: [2 days, 18:52:17] Step: 11661  Batch: 594  D_Loss: 0.666128  G_Loss: 2.102265
2023-02-06 06:20:57 INFO: Time taken for epoch: 3:58:49

2023-02-06 06:20:57 INFO: Epoch: [15]
2023-02-06 06:21:19 INFO: Elapsed: [2 days, 19:13:44] Step: 11719  Batch: 1  D_Loss: 0.896082  G_Loss: 1.644915
2023-02-06 06:45:06 INFO: Elapsed: [2 days, 19:37:32] Step: 11784  Batch: 66  D_Loss: 1.072757  G_Loss: 0.587412
2023-02-06 07:09:15 INFO: Elapsed: [2 days, 20:01:41] Step: 11850  Batch: 132  D_Loss: 0.977338  G_Loss: 0.998172
2023-02-06 07:33:24 INFO: Elapsed: [2 days, 20:25:50] Step: 11916  Batch: 198  D_Loss: 1.117834  G_Loss: 1.814877
2023-02-06 07:57:35 INFO: Elapsed: [2 days, 20:50:00] Step: 11982  Batch: 264  D_Loss: 0.943249  G_Loss: 1.337536
2023-02-06 08:21:45 INFO: Elapsed: [2 days, 21:14:11] Step: 12048  Batch: 330  D_Loss: 0.884948  G_Loss: 1.060483
2023-02-06 08:45:48 INFO: Elapsed: [2 days, 21:38:13] Step: 12114  Batch: 396  D_Loss: 0.799081  G_Loss: 1.650552
2023-02-06 09:09:58 INFO: Elapsed: [2 days, 22:02:24] Step: 12180  Batch: 462  D_Loss: 0.783900  G_Loss: 1.268786
2023-02-06 09:34:08 INFO: Elapsed: [2 days, 22:26:33] Step: 12246  Batch: 528  D_Loss: 1.292123  G_Loss: 0.854290
2023-02-06 09:58:18 INFO: Elapsed: [2 days, 22:50:43] Step: 12312  Batch: 594  D_Loss: 1.498671  G_Loss: 0.372584
2023-02-06 10:20:14 INFO: Time taken for epoch: 3:59:16

2023-02-06 10:20:14 INFO: Epoch: [16]
2023-02-06 10:20:35 INFO: Elapsed: [2 days, 23:13:01] Step: 12370  Batch: 1  D_Loss: 0.928706  G_Loss: 1.258809
2023-02-06 10:44:23 INFO: Elapsed: [2 days, 23:36:49] Step: 12435  Batch: 66  D_Loss: 1.117523  G_Loss: 1.964864
2023-02-06 11:08:35 INFO: Elapsed: [3 days, 0:01:00] Step: 12501  Batch: 132  D_Loss: 0.772543  G_Loss: 1.949255
2023-02-06 11:32:49 INFO: Elapsed: [3 days, 0:25:15] Step: 12567  Batch: 198  D_Loss: 0.893902  G_Loss: 1.186145
2023-02-06 11:57:03 INFO: Elapsed: [3 days, 0:49:28] Step: 12633  Batch: 264  D_Loss: 0.853932  G_Loss: 1.789938
2023-02-06 12:21:16 INFO: Elapsed: [3 days, 1:13:42] Step: 12699  Batch: 330  D_Loss: 0.824457  G_Loss: 1.537009
2023-02-06 12:45:32 INFO: Elapsed: [3 days, 1:37:57] Step: 12765  Batch: 396  D_Loss: 0.667365  G_Loss: 1.717683
2023-02-06 13:09:46 INFO: Elapsed: [3 days, 2:02:12] Step: 12831  Batch: 462  D_Loss: 0.876566  G_Loss: 2.466580
2023-02-06 13:34:32 INFO: Elapsed: [3 days, 2:26:57] Step: 12897  Batch: 528  D_Loss: 0.989047  G_Loss: 0.839439
2023-02-06 13:58:46 INFO: Elapsed: [3 days, 2:51:12] Step: 12963  Batch: 594  D_Loss: 1.218781  G_Loss: 1.198830
2023-02-06 14:19:45 INFO: Time taken for epoch: 3:59:31

2023-02-06 14:19:46 INFO: Saving the model to: ./output/models/GAN_GEN_8.pth

2023-02-06 14:19:47 INFO: Training completed.

